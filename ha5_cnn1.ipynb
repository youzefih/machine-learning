{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS596 Machine Learning \n",
    "# Homework Assignment 5 (Part 1): Convolutional Neural Network\n",
    "\n",
    "### Due 11:59 pm, Friday, 11/16/2018\n",
    "\n",
    "**Total credits: 5**\n",
    "\n",
    "In Part 1 of HA5, you will first implement the following operations with numpy:\n",
    "- Zero padding\n",
    "- Single position convolution\n",
    "- Forward pass for convolution layer\n",
    "- Forward pass for pooling layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.1 Zero padding\n",
    "**0.5 credit**\n",
    "\n",
    "Apply padding around the border of an input image. \n",
    "\n",
    "A batch of inpurt images is represented by a 4-D array of shape (m, n_H, n_W, n_C). You need to pad the 2nd and 3rd dimensions (height and width) with zeros. Use the __[np.pad](https://docs.scipy.org/doc/numpy-1.15.1/reference/generated/numpy.pad.html)__ function for convenience. For example, if you want to pad the input array \"a\" of shape (7,7,7,7,7) with pad_size = 2 for the 2nd dimension and pad_size = 1 for the 4th dimension, with pad_values = 0, then you can write:\n",
    "\n",
    "```python\n",
    "a_pad = np.pad(a, ((0,0), (2,2), (0,0), (1,1), (0,0)), 'constant', constant_value=0)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_pad(X, pad):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    X -- a numpy array of shape (m, n_H, n_W, n_C) representing a batch of images\n",
    "    pad -- an integer indicating the size of padding\n",
    "    \n",
    "    Returns:\n",
    "    X_pad -- a padded array of shape (m, n_H + 2*pad, n_W + 2*pad, n_C)\n",
    "    \"\"\"\n",
    "    ### START TODO ###\n",
    "    X_pad = np.pad(X, ((0, 0), (pad, pad), (pad, pad), (0, 0)), 'constant', constant_values=(0, 0))\n",
    "    ### END TODO ###\n",
    "    \n",
    "    return X_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape = (4, 2, 2, 2)\n",
      "x_pad.shape = (4, 4, 4, 2)\n",
      "x[0,:,:,0] = [[-0.41675785 -2.1361961 ]\n",
      " [-1.79343559  0.50288142]]\n",
      "x_pad[0,:,:,0] = [[ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.41675785 -2.1361961   0.        ]\n",
      " [ 0.         -1.79343559  0.50288142  0.        ]\n",
      " [ 0.          0.          0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Task 1.1\n",
    "np.random.seed(2)\n",
    "x = np.random.randn(4, 2, 2, 2)\n",
    "x_pad = zero_pad(x, 1)\n",
    "print (\"x.shape =\", x.shape)\n",
    "print (\"x_pad.shape =\", x_pad.shape)\n",
    "print (\"x[0,:,:,0] =\", x[0,:,:,0])\n",
    "print (\"x_pad[0,:,:,0] =\", x_pad[0,:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected output\n",
    "\n",
    "|&nbsp;|&nbsp; |          \n",
    "|--|--|\n",
    "|**x.shape =**|(4, 2, 2, 2)|\n",
    "|**x_pad.shape =**|(4, 4, 4, 2)|\n",
    "|**x[0,:,:,0] =**|[[-0.41675785 -2.1361961 ]<br>[-1.79343559  0.50288142]]|\n",
    "|**x_pad[0,:,:,0] =**|[[ 0.          0.          0.          0.        ]<br>[ 0.         -0.41675785 -2.1361961   0.        ]<br>[ 0.         -1.79343559  0.50288142  0.        ]<br>[ 0.          0.          0.          0.        ]]|\n",
    "\n",
    "***\n",
    "\n",
    "### Task 1.2 Single position convolution\n",
    "**1 credit**\n",
    "\n",
    "Implement convolution on a single position of input data, i.e., applying a filter on a slice of input data (same shape as filter). A filter is represented by $W$ the weight matrix of shape (f, f, n_C_prev), and $b$ the bias parameter of shape $(1,1,1)$. You compute the element-wise product between the filter and input, and sum up the result.\n",
    "\n",
    "*Hint:* use `np.multiply` and `np.sum`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_single_pos(a_slice_prev, W, b):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    a_slice_prev -- a slice of the input data, shape = (f, f, n_C_prev)\n",
    "    W -- Weight parameters of the filter, shape = (f, f, n_C_prev)\n",
    "    b -- Bias paramter of the filter, shape = (1, 1, 1)\n",
    "    \n",
    "    Returns:\n",
    "    Z -- A scalar value, result of convlution.\n",
    "    \"\"\"\n",
    "    ### START TODO ###\n",
    "    # Compute the element-wise product between a_slice_prev and W\n",
    "    s = np.multiply(a_slice_prev, W)\n",
    "    # Sum over all entries in volume s\n",
    "    Z = np.sum(s)\n",
    "    # Add bias to Z. Cast b to a float() so that Z results in a scalar value.\n",
    "    Z = Z + float(b)\n",
    "    ### END TODO ###\n",
    "    \n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z = -6.999089450680221\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Task 1.2\n",
    "np.random.seed(1)\n",
    "a_slice_prev = np.random.randn(4, 4, 3)\n",
    "W = np.random.randn(4, 4, 3)\n",
    "b = np.random.randn(1, 1, 1)\n",
    "\n",
    "Z = conv_single_pos(a_slice_prev, W, b)\n",
    "print(\"Z =\", Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected output\n",
    "\n",
    "|&nbsp;|&nbsp; |          \n",
    "|--|--|\n",
    "|**Z =**|-6.999089450680221|\n",
    "\n",
    "***\n",
    "\n",
    "### Task 1.3 Forward pass for convolution layer\n",
    "**2 credits**\n",
    "\n",
    "In the forward pass of a convolution layer, you take several filters and convolve them on the input. The convolution of each filter outputs a 2-D matrix. You stack these matrices and get the final output, a 3-D volume. Here, input is the activation from the previous layer `A_prev`. You use a moving window to select a slice from `A_prev`, and then convolve the slice with the filter denoted by `W` (weight parameters) and `b` (bias parameters).\n",
    "\n",
    "For example, to select a $2\\times 2$ slice from `a_prev`, a volume of shape (5, 5, 3), what you can do is:\n",
    "```python\n",
    "a_prev_slice = a_prev[0:2, 0:2, 0]\n",
    "```\n",
    "\n",
    "To select a slice at an arbitrary position, you need to use the indices of its four corners: `vert_start`, `vert_end`, `horiz_start` and `horiz_end`. In the example above, `vert_start = horiz_start = 0`, and `vert_end = horiz_end = 2`. In any other specific cases, the values of these four corner indices are determined by filter size `f`, stride size `s`, and the position of the corresponding output unit.\n",
    "\n",
    "**Instructions**\n",
    "- Weight parameters `W` is of shape (f, f, n_C_prev, n_C). n_C_prev is the number of channels in the previous layer, and n_C is the number of filters.\n",
    "- Bias parameter `b` is of shape (1, 1, 1, n_C).\n",
    "- Hyperparamters like `stride` and `pad` are stored in the Python dictionary object `hparams`.\n",
    "- Output is of shape (m, n_H, n_W, n_C). n_H and n_W are computed by:\n",
    "    - $n_H = \\lfloor\\frac{n_{H\\ prev} - f - 2\\times p}{s}\\rfloor + 1$\n",
    "    - $n_W = \\lfloor\\frac{n_{W\\ prev} - f - 2\\times p}{s}\\rfloor + 1$\n",
    "    - Each entry in the output volume is computed by calling `conv_single_pos`\n",
    "- The input volume `A_prev` has 4 dimensions, (m, n_H_prev, n_W_prev, n_C_prev), in which m is the number of training examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_forward(A_prev, W, b, hparams):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    A_prev -- Activations from the previous layer, a numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    W -- Weight parameters, a numpy array of shape (f, f, n_C_prev, n_C)\n",
    "    b -- Bias parameters, a numpy array of shape (1, 1, 1, n_C)\n",
    "    hparams -- A Python dict object containing 'stride' and 'pad'\n",
    "    \n",
    "    Returns:\n",
    "    Z -- Output of convolution, a numpy array of shape (m, n_H, n_W, n_C)\n",
    "    cache -- cache of variables needed for backward propagation\n",
    "    \"\"\"\n",
    "    ### START TODO ###\n",
    "    # Retrieve dimensions of input (A_prev)\n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) =A_prev.shape\n",
    "    \n",
    "    # Retrieve dimensions of filter (W)\n",
    "    (f, f, n_C_prev, n_C) = W.shape\n",
    "    \n",
    "    # Retrieve hyperparameters\n",
    "    stride = hparams['stride']\n",
    "    pad = hparams['pad']\n",
    "\n",
    "    # Compute n_H and n_W. Hint: use int() to floor\n",
    "    n_H = int((n_H_prev - f + (2 * pad)) / stride + 1)\n",
    "    n_W = int((n_W_prev - f + (2 * pad)) / stride + 1)\n",
    "    \n",
    "    # Initialize the output volume Z with zeros (into the right shape).\n",
    "    Z = np.zeros((m, n_H, n_W, n_C))\n",
    "    \n",
    "    # Create A_prev_pad by padding A_prev. Hint: call zero_pad()\n",
    "    A_prev_pad = zero_pad(A_prev, pad)\n",
    "    \n",
    "    for i in range(m):                       # Loop over all training examples\n",
    "        # Select the padded activation for the ith training example\n",
    "        a_prev_pad = A_prev[i] \n",
    "        \n",
    "        for h in range(n_H):                 # Loop over vertical axis of the output volume\n",
    "            for w in range(n_W):             # Loop over horizontal axis of the output volume\n",
    "                for c in range(n_C):         # Lopp over Channels of the output volume\n",
    "                    \n",
    "                    # Find the corner indices of the current slice\n",
    "                    vert_start = stride * h\n",
    "                    vert_end = stride * h + f\n",
    "                    horiz_start = stride * w\n",
    "                    horiz_end = stride * w + f\n",
    "                    \n",
    "                    # Use the corner indices defined above to find a slice from a_prev_pad\n",
    "                    a_prev_slice = A_prev_pad[i, vert_start:vert_end, horiz_start:horiz_end, :]\n",
    "                    \n",
    "                    # Convolve the slice with the filter (W and b). Hint: call conv_single_pos()\n",
    "                    Z[i, h, w, c] = conv_single_pos(a_prev_slice, W[:,:,:,c], b[:,:,:,c])\n",
    "                    #a_slice_prev, W, b\n",
    "    ### END TODO ###\n",
    "    \n",
    "    assert(Z.shape == (m, n_H, n_W, n_C))\n",
    "    \n",
    "    # Save to cache\n",
    "    cache = (A_prev, W, b, hparams)\n",
    "    \n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Z = 0.048995203528855794\n",
      "Z[3,2,1] = [-0.61490741 -6.7439236  -2.55153897  1.75698377  3.56208902  0.53036437\n",
      "  5.18531798  8.75898442]\n",
      "cache_conv[0][1][2][3] = [-0.20075807  0.18656139  0.41005165]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Task 1.3\n",
    "np.random.seed(1)\n",
    "A_prev = np.random.randn(10,4,4,3)\n",
    "W = np.random.randn(2,2,3,8)\n",
    "b = np.random.randn(1,1,1,8)\n",
    "hparams = {\"stride\": 2, \"pad\" : 2}\n",
    "\n",
    "Z, cache = conv_forward(A_prev, W, b, hparams)\n",
    "print(\"Mean of Z =\", np.mean(Z))\n",
    "print(\"Z[3,2,1] =\", Z[3,2,1])\n",
    "print(\"cache_conv[0][1][2][3] =\", cache[0][1][2][3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected output\n",
    "\n",
    "|&nbsp;|&nbsp; |          \n",
    "|--|--|\n",
    "|**Mean of Z =**|0.048995203528855794|\n",
    "|**Z[3,2,1] =**|[-0.61490741 -6.7439236  -2.55153897  1.75698377  3.56208902  0.53036437  5.18531798  8.75898442]|\n",
    "|**cache[0][1][2][3] =**|[-0.20075807  0.18656139  0.41005165]|\n",
    "\n",
    "***\n",
    "\n",
    "### Task 1.4 Forward pass for pooling layer\n",
    "**1.5 credits**\n",
    "\n",
    "Max pooling layer slides a window over the input and stores the max value within the window to the output. Average pooling layer computes the average value of the window and stores it to the output.\n",
    "\n",
    "**Instructions:**\n",
    "- Implement the two types of pooling in one function. The type (max or average) of pooling is decided by the argument `mode`\n",
    "- For max pooling, use `np.max()`; for average pooling, use `np.mean()`.\n",
    "- Pooling layer applies no padding, therefore\n",
    "    - $n_H = \\lfloor\\frac{n_{H\\ prev} - f}{s}\\rfloor + 1$\n",
    "    - $n_W = \\lfloor\\frac{n_{W\\ prev} - f}{s}\\rfloor + 1$\n",
    "- Pooling applies to each input channel independently, i.e., $n_C = n_{C_{prev}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool_forward(A_prev, hparams, mode='max'):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    A_prev -- Activations from the previous layer, a numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    hparams -- A Python dict object containing 'stride' and 'pad'\n",
    "    mode -- Pooling type, a string ('max' or 'average')\n",
    "    \n",
    "    Returns:\n",
    "    A -- Output, a numpy array of shape (m, n_H, n_W, n_C)\n",
    "    cache -- Cached variables that will be used for backward propagation \n",
    "    \"\"\"\n",
    "    ### START TODO ###\n",
    "    # Retrieve dimensions of input (A_prev)\n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
    "    \n",
    "    # Retrieve hyperparameters\n",
    "    f = hparams[\"f\"]\n",
    "    stride = hparams[\"stride\"]\n",
    "    \n",
    "    # Compute n_H, n_W and n_C\n",
    "    n_H = int(1 + (n_H_prev - f) / stride)\n",
    "    n_W = int(1 + (n_W_prev - f) / stride)\n",
    "    n_C =  n_C_prev\n",
    "    \n",
    "    # Initialize output volume to zeros\n",
    "    A = np.zeros((m, n_H, n_W, n_C))\n",
    "    \n",
    "    for i in range(m):                       # Loop over all training examples\n",
    "        for h in range(n_H):                 # Loop over vertical axis of the output volume\n",
    "            for w in range(n_W):             # Loop over horizontal axis of the output volume\n",
    "                for c in range(n_C):         # Lopp over Channels of the output volume\n",
    "                    \n",
    "                    # Find the corner indices of the current slice\n",
    "                    vert_start = stride * w\n",
    "                    vert_end = None\n",
    "                    horiz_start = None\n",
    "                    horiz_end = None\n",
    "                    \n",
    "                    # Use the corner indices defined above to find a slice from A_prev\n",
    "                    a_prev_slice = None\n",
    "                    \n",
    "                    # Conduct pooling operation\n",
    "                    if mode == \"max\":\n",
    "                        A[i, h, w, c] = None\n",
    "                    elif mode == \"average\":\n",
    "                        A[i, h, w, c] = None\n",
    "                    \n",
    "    ### END TODO ###\n",
    "    \n",
    "    assert(A.shape == (m, n_H, n_W, n_C))\n",
    "    \n",
    "    # Save to cache\n",
    "    cache = (A_prev, hparams)\n",
    "    \n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Task 1.4\n",
    "np.random.seed(1)\n",
    "A_prev = np.random.randn(2, 4, 4, 3)\n",
    "hparams = {\"stride\" : 2, \"f\": 3}\n",
    "\n",
    "A, cache = pool_forward(A_prev, hparams)\n",
    "print(\"Max pooling = \", A)\n",
    "print()\n",
    "A, cache = pool_forward(A_prev, hparams, mode = \"average\")\n",
    "print(\"Average pooling = \", A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected output\n",
    "\n",
    "|&nbsp;|&nbsp; |          \n",
    "|--|--|\n",
    "|**Max pooling =**|[[[[1.74481176 0.86540763 1.13376944]]]<br>[[[1.13162939 1.51981682 2.18557541]]]]|\n",
    "|**Average pooling =**|[[[[ 0.02105773 -0.20328806 -0.40389855]]]<br>[[[-0.22154621  0.51716526  0.48155844]]]]|\n",
    "\n",
    "***\n",
    "\n",
    "### Congratulations!\n",
    "Now you understand how the forward pass of convolution layer and pooling layer work."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
